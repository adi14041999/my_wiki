
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A personal wiki for notes, ideas, and projects.">
      
      
      
        <link rel="canonical" href="https://adi14041999.github.io/my_wiki/ai/deep_generative_models/energy_based_models/">
      
      
        <link rel="prev" href="../generative_adversarial_networks/">
      
      
        <link rel="next" href="../score_based_models/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Energy Based Models - My Wiki</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#energy-based-models" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="My Wiki" class="md-header__button md-logo" aria-label="My Wiki" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            My Wiki
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Energy Based Models
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../introduction/" class="md-tabs__link">
          
  
  
  AI

        </a>
      </li>
    
  

    
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../math/linear_algebra/vectors_vector_addition_and_scalar_multiplication/" class="md-tabs__link">
          
  
  
  Math

        </a>
      </li>
    
  

    
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../productivity/how_to_build_your_career_in_ai/three_steps_to_career_growth/" class="md-tabs__link">
          
  
  
  Productivity

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="My Wiki" class="md-nav__button md-logo" aria-label="My Wiki" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    My Wiki
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    AI
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            AI
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" checked>
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Deep Generative Models
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            Deep Generative Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../autoregressive_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Autoregressive Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../variational_autoencoders/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Variational Autoencoders
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../normalizing_flow_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Normalizing flow models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../recap_at_this_point/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Recap at this point
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../generative_adversarial_networks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Generative Adversarial Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Energy Based Models
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Energy Based Models
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#parameterizing-probability-distributions" class="md-nav__link">
    <span class="md-ellipsis">
      Parameterizing Probability Distributions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#energy-based-models_1" class="md-nav__link">
    <span class="md-ellipsis">
      Energy Based Models
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-ebms-with-contrastive-divergence" class="md-nav__link">
    <span class="md-ellipsis">
      Training EBMs with Contrastive Divergence
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#contrastive-divergence-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Contrastive Divergence Algorithm
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Contrastive Divergence Algorithm">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#high-level-idea" class="md-nav__link">
    <span class="md-ellipsis">
      High-Level Idea
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-does-this-work" class="md-nav__link">
    <span class="md-ellipsis">
      Why Does This Work?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sampling-from-ebms-with-markov-monte-carlo-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Sampling from EBMs with Markov Monte Carlo Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Sampling from EBMs with Markov Monte Carlo Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#metropolis-hastings-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      Metropolis-Hastings Algorithm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unadjusted-langevin-mcmc" class="md-nav__link">
    <span class="md-ellipsis">
      Unadjusted Langevin MCMC
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../score_based_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Score Based Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../score_based_generative_modeling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Score Based Generative Modeling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../evaluating_generative_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Evaluating Generative Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../score_based_diffusion_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Score Based Diffusion Models
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Math
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Math
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Linear Algebra
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            Linear Algebra
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/linear_algebra/vectors_vector_addition_and_scalar_multiplication/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Vectors, vector addition, and scalar multiplication
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/linear_algebra/vector_geometry_in_mathbb_r_n_and_correlation_coefficients/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Vector geometry in Rn and correlation coefficients
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/linear_algebra/planes_in_r3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Planes in R3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/linear_algebra/span_subspaces_and_dimension/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Span, subspaces, and dimension
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/linear_algebra/basis_and_orthogonality/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Basis and orthogonality
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/linear_algebra/projections/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Projections
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/linear_algebra/applications_of_projections_in_rn_orthogonal_bases_of_planes_and_linear_regression/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Applications of projections in Rn- orthogonal bases of planes and linear regression
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Probability
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            Probability
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/probability_and_counting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Probability and Counting
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/story_proofs_and_axioms_of_probability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Story Proofs and Axioms of Probability
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/conditional_probability/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Conditional Probability
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/some_famous_problems/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Some famous problems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/random_variables/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Random Variables
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/expectation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Expectation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/indicator_random_variables/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Indicator Random Variables
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/poisson_distribution/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Poisson Distribution
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/continuous_distributions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Continuous Distributions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/normal_distribution/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Normal Distribution
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/exponential_distribution/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Exponential Distribution
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/joint_distributions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Joint Distributions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/independence_of_random_variables/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Independence of Random Variables
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/conditional_distributions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Conditional Distributions
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/multinomial_distribution/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Multinomial Distribution
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/covariance_and_correlation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Covariance and Correlation
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Productivity
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Productivity
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    How to Build Your Career in AI
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            How to Build Your Career in AI
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../productivity/how_to_build_your_career_in_ai/three_steps_to_career_growth/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Three Steps to Career Growth
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../productivity/how_to_build_your_career_in_ai/phase_1_learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Phase 1- Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../productivity/how_to_build_your_career_in_ai/phase_2_projects/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Phase 2- Projects
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../productivity/how_to_build_your_career_in_ai/phase_3_job/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Phase 3- Job
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="energy-based-models">Energy-Based Models</h1>
<h2 id="parameterizing-probability-distributions">Parameterizing Probability Distributions</h2>
<p>Probability distributions <span class="arithmatex">\(p(x)\)</span> are a key building block in generative modeling. Building a neural network that ensures <span class="arithmatex">\(p(x) \geq 0\)</span> is not hard. However, the real challenge lies in ensuring that the distribution satisfies the normalization constraint: for discrete variables, the sum over all possible values of <span class="arithmatex">\(x\)</span> must equal 1, while for continuous variables, the integral over the entire domain must equal 1.</p>
<p><strong>Problem:</strong> <span class="arithmatex">\(g_\theta(x) \geq 0\)</span> is easy. But <span class="arithmatex">\(\sum_x g_\theta(x) = Z(\theta) \neq 1\)</span> in general, so <span class="arithmatex">\(g_\theta(x)\)</span> is not a valid probability mass function. For continuous variables, <span class="arithmatex">\(\int g_\theta(x) dx = Z(\theta) \neq 1\)</span> in general, so <span class="arithmatex">\(g_\theta(x)\)</span> is not a valid probability density function.</p>
<p><strong>Solution:</strong></p>
<div class="arithmatex">\[p_\theta(x) = \frac{1}{Z(\theta)} g_\theta(x) = \frac{1}{\int g_\theta(x) dx} g_\theta(x) = \frac{1}{\text{Volume}(g_\theta)} g_\theta(x)\]</div>
<p>Then by definition,</p>
<div class="arithmatex">\[\int p_\theta(x) dx = \int \frac{1}{Z(\theta)} g_\theta(x) dx = \frac{Z(\theta)}{Z(\theta)} = 1\]</div>
<p>Here, <span class="arithmatex">\(g_\theta(x)\)</span> is the output of the neural network with parameters <span class="arithmatex">\(\theta\)</span> at input <span class="arithmatex">\(x\)</span>. The <strong>volume</strong> of <span class="arithmatex">\(g_\theta\)</span>, denoted as <span class="arithmatex">\(\text{Volume}(g_\theta)\)</span>, is defined as the integral of <span class="arithmatex">\(g_\theta(x)\)</span> over the entire domain: <span class="arithmatex">\(\text{Volume}(g_\theta) = \int g_\theta(x) dx = Z(\theta)\)</span>. It is a normalizing constant (w.r.t. <span class="arithmatex">\(x\)</span>) but changes for different <span class="arithmatex">\(\theta\)</span>. For example, we choose <span class="arithmatex">\(g_\theta(x)\)</span> so that we know the volume analytically as a function of <span class="arithmatex">\(\theta\)</span>.</p>
<p>The <strong>partition function</strong> <span class="arithmatex">\(Z(\theta)\)</span> is the normalization constant that ensures a probability distribution integrates (or sums) to 1. It's called a "partition function" because it partitions the unnormalized function <span class="arithmatex">\(g_\theta(x)\)</span> into a proper probability distribution.</p>
<p><strong>Example:</strong> <span class="arithmatex">\(g_{(\mu, \sigma)}(x) = e^{-\frac{(x-\mu)^2}{2\sigma^2}}\)</span></p>
<div class="arithmatex">\[\text{Volume}(g_{(\mu, \sigma)}) = \int_{-\infty}^{\infty} e^{-\frac{(x-\mu)^2}{2\sigma^2}} dx = \sqrt{2\pi\sigma^2}\]</div>
<p>Therefore, the normalized probability density function is:</p>
<div class="arithmatex">\[p_{(\mu, \sigma)}(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]</div>
<p>This is the standard normal (Gaussian) distribution with mean <span class="arithmatex">\(\mu\)</span> and variance <span class="arithmatex">\(\sigma^2\)</span>.
Functional forms <span class="arithmatex">\(g_\theta(x)\)</span> need to allow analytical integration. Despite being restrictive, they are very useful as building blocks for more complex distributions.</p>
<p><strong>Note:</strong> What we've been doing with autoregressive models, flow models, and VAEs are essentially tricks for composing simple functions that are normalized to build more complex probabilistic models that are by construction guaranteed to be normalized. These approaches avoid the intractability of computing the partition function for complex distributions by designing architectures where normalization is preserved through the composition of simple, analytically tractable components.</p>
<h2 id="energy-based-models_1">Energy Based Models</h2>
<p>We are going to formalize EBMs the following way:</p>
<div class="arithmatex">\[p_\theta(x) = \frac{1}{\int e^{f_\theta(x)} dx} \cdot e^{f_\theta(x)}\]</div>
<div class="arithmatex">\[p_\theta(x) = \frac{1}{Z(\theta)} \cdot e^{f_\theta(x)}\]</div>
<p><strong>Why <span class="arithmatex">\(e^{f_\theta(x)}\)</span> and not <span class="arithmatex">\(f_\theta(x)^2\)</span>?</strong></p>
<p>Both <span class="arithmatex">\(e^{f_\theta(x)}\)</span> and <span class="arithmatex">\(f_\theta(x)^2\)</span> produce non-negative outputs, but we choose the exponential form for several important reasons:</p>
<ol>
<li>
<p><strong>Additive Energy</strong>: The exponential form allows us to work with additive energy functions. If we have <span class="arithmatex">\(f_\theta(x) = f_1(x) + f_2(x)\)</span>, then <span class="arithmatex">\(e^{f_\theta(x)} = e^{f_1(x)} \cdot e^{f_2(x)}\)</span>, which is a natural way to combine energy terms.</p>
</li>
<li>
<p><strong>Log-Probability Interpretation</strong>: Taking the logarithm gives us <span class="arithmatex">\(\log p_\theta(x) = f_\theta(x) - \log Z(\theta)\)</span>. This means <span class="arithmatex">\(f_\theta(x)\)</span> directly represents the unnormalized log-probability, making it easier to work with in practice.</p>
</li>
<li>
<p><strong>Gradient Properties</strong>: The exponential function has the property that <span class="arithmatex">\(\frac{d}{dx}e^{f(x)} = e^{f(x)} \cdot f'(x)\)</span>. This makes gradient-based learning more stable and interpretable.</p>
</li>
<li>
<p><strong>Numerical Stability</strong>: The exponential function grows more smoothly than quadratic functions, which can lead to better numerical stability during training.</p>
</li>
<li>
<p><strong>Dynamic Range</strong>: The exponential function can capture much larger variations in probability compared to quadratic functions. While <span class="arithmatex">\(f_\theta(x)^2\)</span> is bounded by the square of the function's range, <span class="arithmatex">\(e^{f_\theta(x)}\)</span> can represent probabilities that vary by many orders of magnitude.</p>
</li>
<li>
<p><strong>Statistical Mechanics Connection</strong>: The exponential form follows from the Boltzmann distribution in statistical mechanics, where <span class="arithmatex">\(p(x) \propto e^{-E(x)/kT}\)</span>, where <span class="arithmatex">\(-E(x)\)</span> is the energy of state <span class="arithmatex">\(x\)</span>. Hence the name.</p>
</li>
</ol>
<p><strong>Pros:</strong>
Very flexible, can use any <span class="arithmatex">\(f_\theta(x)\)</span></p>
<p><strong>Cons:</strong>
<span class="arithmatex">\(Z(\theta)\)</span> is intractable, so no access to likelihood. Thus, evaluating and optimizing likelihood <span class="arithmatex">\(p_\theta(x)\)</span> is hard (learning is hard). Also, sampling from <span class="arithmatex">\(p_\theta(x)\)</span> is hard. Another con is there is no feature learning (but can add latent variables). EBMs also suffer from the curse of dimensionality - as the dimension of <span class="arithmatex">\(x\)</span> increases, the volume of the space grows exponentially, making it increasingly difficult to learn meaningful energy functions and sample efficiently.</p>
<p>Given two points <span class="arithmatex">\(x_1\)</span> and <span class="arithmatex">\(x_2\)</span>, evaluating <span class="arithmatex">\(p_\theta(x_1)\)</span> or <span class="arithmatex">\(p_\theta(x_2)\)</span> requires calculating <span class="arithmatex">\(Z(\theta)\)</span>. However, their ratio does not involve calculating <span class="arithmatex">\(Z(\theta)\)</span>.</p>
<div class="arithmatex">\[\frac{p_\theta(x_1)}{p_\theta(x_2)} = \frac{\frac{1}{Z(\theta)} \cdot e^{f_\theta(x_1)}}{\frac{1}{Z(\theta)} \cdot e^{f_\theta(x_2)}} = \frac{e^{f_\theta(x_1)}}{e^{f_\theta(x_2)}} = e^{f_\theta(x_1) - f_\theta(x_2)}\]</div>
<p>The partition function <span class="arithmatex">\(Z(\theta)\)</span> cancels out in the ratio, so we only need to evaluate the energy function at the two points and take their difference. This means we can determine which of <span class="arithmatex">\(x_1\)</span> or <span class="arithmatex">\(x_2\)</span> is more likely under our model without needing to compute the intractable partition function.</p>
<h2 id="training-ebms-with-contrastive-divergence">Training EBMs with Contrastive Divergence</h2>
<p><img alt="Dataset" src="../ebm_training.png" /></p>
<p>Let's assume we want to maximize <span class="arithmatex">\(\frac{\exp(f_\theta(x_{train}))}{Z(\theta)}\)</span>. <span class="arithmatex">\(x_{train}\)</span> is the 'correct answer'- we want to increase the probability of this under the model. Let's also assume we have a 'wrong answer'. The objective is to not just maximize <span class="arithmatex">\(\exp(f_\theta(x_{train}))\)</span> but also minimize <span class="arithmatex">\(Z(\theta)\)</span> because that's going to result in the 'wrong' answer being pushed down.</p>
<p>Instead of evaluating <span class="arithmatex">\(Z(\theta)\)</span> exactly, we use a Monte Carlo estimate.</p>
<h2 id="contrastive-divergence-algorithm">Contrastive Divergence Algorithm</h2>
<h3 id="high-level-idea"><strong>High-Level Idea</strong></h3>
<p>The contrastive divergence algorithm works as follows:</p>
<p><strong>Algorithm:</strong></p>
<ol>
<li>
<p>Assuming we can sample from the model, sample <span class="arithmatex">\(x_{sample} \sim p_\theta\)</span></p>
</li>
<li>
<p>Take a step on the gradient: <span class="arithmatex">\(\nabla_\theta(f_\theta(x_{train}) - f_\theta(x_{sample}))\)</span></p>
</li>
<li>
<p>Keep repeating this to make the training data more likely than typical samples from the model</p>
</li>
</ol>
<h3 id="why-does-this-work"><strong>Why Does This Work?</strong></h3>
<p>We want to maximize the log-likelihood: <span class="arithmatex">\(\max_\theta(f_\theta(x_{train}) - \log Z(\theta))\)</span></p>
<p><strong>Mathematical Derivation:</strong></p>
<p>The gradient of the log-likelihood is:</p>
<div class="arithmatex">\[\nabla_\theta \log p_\theta(x_{train}) = \nabla_\theta(f_\theta(x_{train}) - \log Z(\theta))\]</div>
<p>Let's split the terms and take the derivative:</p>
<div class="arithmatex">\[\nabla_\theta \log p_\theta(x_{train}) = \nabla_\theta f_\theta(x_{train}) - \nabla_\theta \log Z(\theta)\]</div>
<p>Now we need to compute <span class="arithmatex">\(\nabla_\theta \log Z(\theta)\)</span>. Let's expand this:</p>
<div class="arithmatex">\[\nabla_\theta \log Z(\theta) = \nabla_\theta \log \int e^{f_\theta(x)} dx\]</div>
<p>Using the chain rule and the fact that <span class="arithmatex">\(\nabla \log f(x) = \frac{\nabla f(x)}{f(x)}\)</span>:</p>
<div class="arithmatex">\[\nabla_\theta \log Z(\theta) = \frac{1}{Z(\theta)} \nabla_\theta \int e^{f_\theta(x)} dx\]</div>
<p>Since the integral and derivative can be exchanged:</p>
<div class="arithmatex">\[\nabla_\theta \log Z(\theta) = \frac{1}{Z(\theta)} \int \nabla_\theta e^{f_\theta(x)} dx\]</div>
<p>Using the chain rule again:</p>
<div class="arithmatex">\[\nabla_\theta \log Z(\theta) = \frac{1}{Z(\theta)} \int e^{f_\theta(x)} \nabla_\theta f_\theta(x) dx\]</div>
<p>Notice that <span class="arithmatex">\(\frac{e^{f_\theta(x)}}{Z(\theta)} = p_\theta(x)\)</span>, so:</p>
<div class="arithmatex">\[\nabla_\theta \log Z(\theta) = \int p_\theta(x) \nabla_\theta f_\theta(x) dx = \mathbb{E}_{x \sim p_\theta}[\nabla_\theta f_\theta(x)]\]</div>
<p><strong>Final Result:</strong></p>
<p>Putting it all together:</p>
<div class="arithmatex">\[\nabla_\theta \log p_\theta(x_{train}) = \nabla_\theta f_\theta(x_{train}) - \mathbb{E}_{x \sim p_\theta}[\nabla_\theta f_\theta(x)]\]</div>
<p><strong>The Key Insight:</strong></p>
<p>The second term <span class="arithmatex">\(\mathbb{E}_{x \sim p_\theta}[\nabla_\theta f_\theta(x)]\)</span> is an expectation over the model distribution. We approximate (Monte Carlo approximation) this expectation using samples from the model:</p>
<div class="arithmatex">\[\mathbb{E}_{x \sim p_\theta}[\nabla_\theta f_\theta(x)] \approx \nabla_\theta f_\theta(x_{sample})\]</div>
<p>where <span class="arithmatex">\(x_{sample} \sim p_\theta\)</span> is a sample from our model.</p>
<p><strong>Important note on sampling:</strong></p>
<p>Unlike autoregressive models or normalizing flow models, Energy-Based Models do not provide a direct way to sample from <span class="arithmatex">\(p_\theta(x)\)</span>. In autoregressive models, we can sample sequentially by conditioning on previous values. In flow models, we can sample from a simple base distribution and transform it through invertible functions. However, in EBMs, we need to use approximate sampling methods like:</p>
<ul>
<li><strong>Langevin Dynamics</strong>: Gradient-based sampling with noise</li>
<li><strong>Gibbs Sampling</strong>: For discrete variables, updating one variable at a time</li>
<li><strong>Metropolis-Hastings</strong>: Markov chain Monte Carlo methods</li>
<li><strong>Hamiltonian Monte Carlo</strong>: More sophisticated MCMC methods</li>
</ul>
<p>This sampling challenge is one of the main difficulties in training EBMs, as we need to run these sampling procedures every time we want to estimate the gradient.</p>
<h2 id="sampling-from-ebms-with-markov-monte-carlo-methods">Sampling from EBMs with Markov Monte Carlo Methods</h2>
<h3 id="metropolis-hastings-algorithm"><strong>Metropolis-Hastings Algorithm</strong></h3>
<p>Metropolis-Hastings (MH) is a general-purpose Markov Chain Monte Carlo (MCMC) method for sampling from complex probability distributions. It's particularly useful for Energy-Based Models where direct sampling is not possible.</p>
<p><strong>The Algorithm</strong></p>
<p><strong>Step 1: Initialize</strong>
Start with an initial sample <span class="arithmatex">\(x^{(0)}\)</span> (could be random or from training data)</p>
<p><strong>Step 2: Propose a New Sample</strong>
For each iteration <span class="arithmatex">\(t\)</span>:</p>
<ul>
<li>
<p>Generate a proposal <span class="arithmatex">\(x^*\)</span> from a proposal distribution <span class="arithmatex">\(q(x^* | x^{(t)})\)</span></p>
</li>
<li>
<p>The proposal distribution should be easy to sample from (e.g., Gaussian centered at current point)</p>
</li>
</ul>
<p><strong>Step 3: Accept or Reject</strong></p>
<p>Compute the acceptance probability:</p>
<div class="arithmatex">\[\alpha = \min\left(1, \frac{e^{f_\theta(x^*)} \cdot q(x^{(t)} | x^*)}{e^{f_\theta(x^{(t)})} \cdot q(x^* | x^{(t)})}\right)\]</div>
<p>The <code>min(1, ...)</code> ensures the acceptance probability is between 0 and 1. When the ratio is &gt; 1, we always accept (probability = 1). When the ratio is â‰¤ 1, we accept with probability equal to the ratio.</p>
<p><strong>Step 4: Update</strong>
With probability <span class="arithmatex">\(\alpha\)</span>, accept the proposal: <span class="arithmatex">\(x^{(t+1)} = x^*\)</span>.
With probability <span class="arithmatex">\(1-\alpha\)</span>, reject and keep current: <span class="arithmatex">\(x^{(t+1)} = x^{(t)}\)</span></p>
<p><strong>Step 5: Repeat</strong>
Continue for many iterations until convergence</p>
<p>This algorithm provides a robust foundation for sampling from Energy-Based Models, though it may require careful tuning and monitoring for optimal performance.</p>
<h3 id="unadjusted-langevin-mcmc"><strong>Unadjusted Langevin MCMC</strong></h3>
<p>Unadjusted Langevin MCMC (ULMCMC) is another popular method for sampling from Energy-Based Models. Unlike Metropolis-Hastings, it doesn't use an accept/reject step, making it computationally more efficient.</p>
<p><strong>The Algorithm</strong></p>
<p><strong>Step 1: Initialize</strong>
Start with an initial sample <span class="arithmatex">\(x^{(0)}\)</span> (could be random or from training data)</p>
<p><strong>Step 2: Langevin Dynamics Update</strong>
For each iteration <span class="arithmatex">\(t\)</span>:</p>
<div class="arithmatex">\[x^{(t+1)} = x^{(t)} + \epsilon \nabla_x f_\theta(x^{(t)}) + \sqrt{2\epsilon} \eta_t\]</div>
<p>where:</p>
<ul>
<li>
<p><span class="arithmatex">\(\epsilon\)</span> is the step size (learning rate)</p>
</li>
<li>
<p><span class="arithmatex">\(\nabla_x f_\theta(x^{(t)})\)</span> is the gradient of the energy function</p>
</li>
<li>
<p><span class="arithmatex">\(\eta_t \sim \mathcal{N}(0, I)\)</span> is Gaussian noise</p>
</li>
</ul>
<p><strong>Step 3: Repeat</strong>
Continue for many iterations until convergence</p>
<p><strong>Intuition</strong></p>
<p>The update rule can be understood as:</p>
<ol>
<li>
<p><strong>Gradient Ascent</strong>: <span class="arithmatex">\(\epsilon \nabla_x f_\theta(x^{(t)})\)</span> moves the sample toward higher energy regions</p>
</li>
<li>
<p><strong>Noise Injection</strong>: <span class="arithmatex">\(\sqrt{2\epsilon} \eta_t\)</span> adds randomness to prevent getting stuck in local optima</p>
</li>
<li>
<p><strong>Balance</strong>: The step size <span class="arithmatex">\(\epsilon\)</span> controls the trade-off between exploration and exploitation</p>
</li>
</ol>
<p><strong>High-Dimensional Expense</strong></p>
<p>In high dimensions, gradient computation becomes expensive, and the noise term <span class="arithmatex">\(\sqrt{2\epsilon} \eta_t\)</span> scales with dimension, making each step computationally costly. This computational burden is particularly problematic when training Energy-Based Models using Contrastive Divergence.</p>
<p><strong>The Training Bottleneck:</strong></p>
<p>Each training step in Contrastive Divergence requires sampling from the model distribution <span class="arithmatex">\(p_\theta(x)\)</span>. This sampling process itself is computationally expensive:</p>
<ol>
<li><strong>Single Sampling Step</strong>: Each Langevin step requires computing gradients and adding noise, both of which scale with dimension</li>
<li><strong>Multiple Sampling Steps</strong>: To get a good sample, we typically need hundreds or thousands of Langevin steps</li>
<li><strong>Per Training Step</strong>: Each gradient update of the model parameters requires multiple samples</li>
</ol>
<p><strong>Computational Complexity:</strong></p>
<ul>
<li><strong>Gradient Computation</strong>: <span class="arithmatex">\(O(d)\)</span> where <span class="arithmatex">\(d\)</span> is the dimension</li>
<li><strong>Noise Generation</strong>: <span class="arithmatex">\(O(d)\)</span> for generating <span class="arithmatex">\(\eta_t \sim \mathcal{N}(0, I)\)</span></li>
<li><strong>Per Langevin Step</strong>: <span class="arithmatex">\(O(d)\)</span> total cost</li>
<li><strong>Sampling Process</strong>: <span class="arithmatex">\(O(k \cdot d)\)</span> where <span class="arithmatex">\(k\)</span> is the number of Langevin steps (typically 100-1000)</li>
<li><strong>Per Training Step</strong>: <span class="arithmatex">\(O(n \cdot k \cdot d)\)</span> where <span class="arithmatex">\(n\)</span> is the number of samples needed</li>
</ul>
<p><strong>Practical Impact:</strong></p>
<p>This means that training an EBM using Contrastive Divergence with Langevin sampling can be extremely slow, especially for high-dimensional data like images. The sampling process becomes the computational bottleneck, making it difficult to scale EBMs to large datasets or high-dimensional problems.</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      &copy; 2025 <a href="https://github.com/adi14041999"  target="_blank" rel="noopener">Aditya Prabhu</a>
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.sections", "toc.integrate", "navigation.top", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>