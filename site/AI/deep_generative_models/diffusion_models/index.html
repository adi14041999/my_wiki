
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A personal wiki for notes, ideas, and projects.">
      
      
      
        <link rel="canonical" href="https://adi14041999.github.io/my_wiki/AI/deep_generative_models/diffusion_models/">
      
      
        <link rel="prev" href="../evaluating_generative_models/">
      
      
        <link rel="next" href="../../../math/probability/probability_and_counting/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Diffusion Models - My Wiki</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#diffusion-models" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="My Wiki" class="md-header__button md-logo" aria-label="My Wiki" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            My Wiki
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Diffusion Models
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../introduction/" class="md-tabs__link">
          
  
  
  AI

        </a>
      </li>
    
  

    
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../math/probability/probability_and_counting/" class="md-tabs__link">
          
  
  
  Math

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="My Wiki" class="md-nav__button md-logo" aria-label="My Wiki" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    My Wiki
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    AI
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            AI
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" checked>
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Deep Generative Models
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            Deep Generative Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../autoregressive_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Autoregressive Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../variational_autoencoders/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Variational Autoencoders
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../normalizing_flow_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Normalizing flow models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../recap_at_this_point/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Recap at this point
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../generative_adversarial_networks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Generative Adversarial Networks
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../energy_based_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Energy Based Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../score_based_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Score Based Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../score_based_generative_modeling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Score Based Generative Modeling
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../evaluating_generative_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Evaluating Generative Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Diffusion Models
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Diffusion Models
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#quick-recap-score-based-models" class="md-nav__link">
    <span class="md-ellipsis">
      Quick Recap: Score Based Models
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction-to-diffusion-models" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction to Diffusion Models
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#forward-encoder" class="md-nav__link">
    <span class="md-ellipsis">
      Forward Encoder
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Forward Encoder">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diffusion-kernel" class="md-nav__link">
    <span class="md-ellipsis">
      Diffusion Kernel
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conditional-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      Conditional distribution
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reverse-decoder" class="md-nav__link">
    <span class="md-ellipsis">
      Reverse Decoder
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Math
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Math
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Probability
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            Probability
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/probability_and_counting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Probability and Counting
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="diffusion-models">Diffusion Models</h1>
<h2 id="quick-recap-score-based-models">Quick Recap: Score Based Models</h2>
<p>From our exploration of score-based generative modeling, we learned several key concepts:</p>
<p><strong>Score Function</strong>: The gradient of the log probability density, <span class="arithmatex">\(\nabla_x \log p(x)\)</span>, which points "uphill" in the probability landscape toward high-density regions.</p>
<p><strong>Score Matching</strong>: A training objective that learns the score function by minimizing the Fisher divergence between the learned and true score functions.</p>
<p><strong>Score Matching Objective</strong>: The original score matching objective is:</p>
<div class="arithmatex">\[\mathcal{L}(\theta) = \mathbb{E}_{x \sim p_{data}(x)} \left[ \frac{1}{2} \| s_\theta(x) \|_2^2 + \text{tr}(\nabla_x s_\theta(x)) \right]\]</div>
<p>where <span class="arithmatex">\(\text{tr}(\nabla_x s_\theta(x))\)</span> is the trace of the Jacobian of the score function, which is computationally expensive to evaluate.</p>
<p><strong>Denoising Score Matching (DSM)</strong>: A practical variant that trains the score function to predict the direction from noisy to clean data, avoiding the need to compute the true score function.</p>
<p><strong>DSM Objective</strong>: The denoising score matching objective is:</p>
<div class="arithmatex">\[\mathcal{L}(\theta) = \mathbb{E}_{y \sim p_{data}(y)} \mathbb{E}_{x \sim \mathcal{N}(x; y, \sigma^2 I)} \left[ \frac{1}{2} \left\| s_\theta(x) - \frac{y - x}{\sigma^2} \right\|_2^2 \right]\]</div>
<p>where <span class="arithmatex">\(s_\theta(x)\)</span> learns to predict the score function of the noise-perturbed distribution, and <span class="arithmatex">\(\frac{y - x}{\sigma^2}\)</span> is the target score function that points from noisy sample <span class="arithmatex">\(x\)</span> toward clean data <span class="arithmatex">\(y\)</span>.</p>
<p><strong>Langevin Dynamics</strong>: A continuous-time stochastic process that uses the score function to guide sampling:</p>
<div class="arithmatex">\[dx_t = \nabla_x \log p(x_t) dt + \sqrt{2} dW_t\]</div>
<p><strong>Discretized Form</strong>: For practical implementation:</p>
<div class="arithmatex">\[x_{t+1} = x_t + \frac{\epsilon}{2} \cdot s_\theta(x_t) + \sqrt{2\epsilon} \cdot \eta_t\]</div>
<p><strong>Mode Collapse</strong>: Standard Langevin dynamics struggles with multi-modal distributions and low-density regions.</p>
<p><strong>Annealed Langevin Dynamics</strong>: Addresses this by using multiple noise scales <span class="arithmatex">\(\sigma_1 &lt; \sigma_2 &lt; \ldots &lt; \sigma_L\)</span>, creating a sequence of increasingly noisy distributions that are easier to sample from.</p>
<p><strong>Stochastic Differential Equations (SDEs)</strong>: General framework for continuous-time stochastic processes:</p>
<div class="arithmatex">\[dx = f(x, t)dt + g(t)dw\]</div>
<p><strong>Reverse SDE</strong>: Any SDE has a corresponding reverse process for sampling:</p>
<div class="arithmatex">\[dx = [f(x, t) - g^2(t)\nabla_x \log p_t(x)]dt + g(t)d\bar{w}\]</div>
<p><strong>Time-Dependent Score Models</strong>: Neural networks that learn <span class="arithmatex">\(s_\theta(x, t) \approx \nabla_x \log p_t(x)\)</span> for continuous-time processes.</p>
<p><strong>Key insights:</strong></p>
<ol>
<li><strong>Score functions act as denoisers</strong>: They point from noisy to clean data</li>
<li><strong>Multiple noise scales help</strong>: Annealing from high to low noise improves sampling</li>
<li><strong>Continuous-time generalizes discrete</strong>: SDEs provide a unified framework</li>
<li><strong>Reverse processes enable generation</strong>: The reverse SDE naturally incorporates the score function for sampling</li>
</ol>
<h2 id="introduction-to-diffusion-models">Introduction to Diffusion Models</h2>
<p>We have seen that a powerful way to construct rich generative models is to introduce a distribution p(z) over a latent variable z, and then to transform z into the data space x using a deep neural network. It is sufficient to use a simple, fixed distribution for p(z), such as a Gaussian N(z|0; I), since the generality of the neural network transforms this into a highly flexible family of distributions over x.</p>
<p>The central idea is to take each training image and to corrupt it using a multi-step noise process to transform it into a sample from a Gaussian distribution.</p>
<p><img alt="Encoding process in a diffusion model" src="../cat_diff.png" /></p>
<p>A deep neural network is then trained to invert this process, and once trained the network can then generate new images starting with samples from a Gaussian as input. Diffusion models can be viewed as a form of hierarchical variational autoencoder in which the encoder distribution is fixed, and defined by the noise process, and only the generative distribution is learned. They are easy to train, they scale well on parallel hardware, and they avoid the challenges and instabilities of adversarial training while producing results that have quality comparable to, or better than, generative adversarial networks. However, generating new samples can be computationally expensive due to the need for multiple forward passes through the decoder network.</p>
<h2 id="forward-encoder">Forward Encoder</h2>
<p>Suppose we take an image from the training set, which we will denote by <span class="arithmatex">\(x\)</span>, and blend it with Gaussian noise independently for each pixel to give a noise-corrupted image <span class="arithmatex">\(z_1\)</span> defined by</p>
<div class="arithmatex">\[z_1 = \sqrt{1 - \beta_1} x + \sqrt{\beta_1} \epsilon_1\]</div>
<p>where <span class="arithmatex">\(\epsilon_1 \sim \mathcal{N}(\epsilon_1|0; I)\)</span> and <span class="arithmatex">\(\beta_1 &lt; 1\)</span> is the variance of the noise distribution. We can write the transformation in the form</p>
<div class="arithmatex">\[q(z_1|x) = \mathcal{N}(z_1|\sqrt{1 - \beta_1} x; \beta_1 I)\]</div>
<p>We then repeat the process with additional independent Gaussian noise steps to give a sequence of increasingly noisy images <span class="arithmatex">\(z_2, \ldots, x_T\)</span>.</p>
<p>Each successive image is given by</p>
<div class="arithmatex">\[z_t = \sqrt{1 - \beta_t} z_{t-1} + \sqrt{\beta_t} \epsilon_t\]</div>
<p>where <span class="arithmatex">\(\epsilon_t \sim \mathcal{N}(\epsilon_t|0; I)\)</span>. Again, we can write this equation in the form</p>
<div class="arithmatex">\[q(z_t|z_{t-1}) = \mathcal{N}(z_t|\sqrt{1 - \beta_t} x_{t-1}; \beta_t I)\]</div>
<p>The choice of coefficients <span class="arithmatex">\(\sqrt{1 - \beta_1}\)</span> and <span class="arithmatex">\(\sqrt{\beta_1}\)</span> ensures that the mean of the distribution of <span class="arithmatex">\(x_t\)</span> is closer to zero than the mean of <span class="arithmatex">\(z_{t-1}\)</span> and that the variance of <span class="arithmatex">\(z_t\)</span> is closer to the unit matrix than the variance of <span class="arithmatex">\(z_{t-1}\)</span>.</p>
<p>The sequence of conditional distributions forms a Markov chain and can be expressed as a probabilistic graphical model. The values of the variance parameters <span class="arithmatex">\(\beta_t \in (0, 1)\)</span> are set by hand and are typically chosen such that the variance values increase through the chain according to a prescribed schedule such that <span class="arithmatex">\(\beta_1 &lt; \beta_2 &lt; \ldots &lt; \beta_T\)</span>.</p>
<h3 id="diffusion-kernel">Diffusion Kernel</h3>
<p>The joint distribution of the latent variables, conditioned on the observed data vector <span class="arithmatex">\(x\)</span>, is given by</p>
<div class="arithmatex">\[q(z_1, \ldots, z_t|x) = q(z_1|x) \prod_{s=2}^t q(z_s|z_{s-1})\]</div>
<p>If we now marginalize over the intermediate variables <span class="arithmatex">\(z_1, \ldots, z_{t-1}\)</span>, we obtain the
diffusion kernel:</p>
<div class="arithmatex">\[q(z_t|x) = \mathcal{N}(z_t|\sqrt{\bar{\alpha}_t} x; (1 - \bar{\alpha}_t)I)\]</div>
<p>where we have defined</p>
<div class="arithmatex">\[\bar{\alpha}_t = \prod_{s=1}^t (1 - \beta_s)\]</div>
<p>We see that each intermediate distribution has a simple closed-form Gaussian expression from which we can directly sample, which will prove useful when training as it allows efficient stochastic gradient descent using randomly chosen intermediate terms in the Markov chain without having to run the whole chain.</p>
<p>Also,</p>
<div class="arithmatex">\[z_t = \sqrt{\bar{\alpha}_t} x + \sqrt{1 - \bar{\alpha}_t} \epsilon_t\]</div>
<p>where again <span class="arithmatex">\(\epsilon_t \sim \mathcal{N}(\epsilon_t|0; I)\)</span>. Note that <span class="arithmatex">\(\epsilon_t\)</span> now represents the total noise added to the original image instead of the incremental noise added at this step of the Markov chain.</p>
<p>After many steps the image becomes indistinguishable from Gaussian noise, and in the limit <span class="arithmatex">\(T \rightarrow \infty\)</span> we have</p>
<div class="arithmatex">\[q(z_T |x) = \mathcal{N}(z_T |0; I)\]</div>
<p>and therefore all information about the original image is lost. The choice of coefficients <span class="arithmatex">\(\sqrt{1 - \bar{\alpha}_t}\)</span> and <span class="arithmatex">\(\sqrt{\bar{\alpha}_t}\)</span> ensures that once the Markov chain converges to a distribution with zero mean and unit covariance, further updates will leave this unchanged.</p>
<p>The marginal distribution of <span class="arithmatex">\(z_T\)</span> is given by</p>
<div class="arithmatex">\[q(z_T) = \mathcal{N}(z_T |0; I)\]</div>
<p>It is common to refer to the Markov chain as the forward process, and it is  analogous to the encoder in a VAE, except that here it is fixed rather than learned.</p>
<h3 id="conditional-distribution">Conditional distribution</h3>
<p>Our goal is to learn to undo the noise process, and so it is natural to consider the reverse of the conditional distribution <span class="arithmatex">\(q(z_t|z_{t-1})\)</span>, which we can express using Bayes' theorem in the form</p>
<div class="arithmatex">\[q(z_{t-1}|z_t) = \frac{q(z_t|z_{t-1})q(z_{t-1})}{q(z_t)}\]</div>
<p>We can write the marginal distribution <span class="arithmatex">\(q(z_{t-1})\)</span> in the form</p>
<div class="arithmatex">\[q(z_{t-1}) = \int q(z_{t-1}|x)p_{data}(x) dx\]</div>
<p>where <span class="arithmatex">\(q(z_{t-1}|x)\)</span> is given by the conditional Gaussian. This distribution is intractable, however, because we must integrate over the unknown data density <span class="arithmatex">\(p_{data}(x)\)</span>.</p>
<p>We consider the conditional version of the reverse distribution, conditioned on the data vector <span class="arithmatex">\(x\)</span>, defined by <span class="arithmatex">\(q(z_{t-1}|z_t, x)\)</span>, which as we will see shortly turns out to be a simple Gaussian distribution. Intuitively this is reasonable since, given a noisy image, it is difficult to guess which lower-noise image gave rise to it, whereas if we also know the starting image then the problem becomes much easier. We can calculate this conditional distribution using Bayes' theorem:</p>
<div class="arithmatex">\[q(z_{t-1}|z_t, x) = \frac{q(z_t|z_{t-1}, x)q(z_{t-1}|x)}{q(z_t|x)}\]</div>
<p>Let's derive this formula step by step using Bayes' theorem and the properties of the diffusion process.</p>
<p>In the general case of <span class="arithmatex">\(n\)</span> random variables <span class="arithmatex">\(X_1, X_2, \ldots, X_n\)</span>, the values of an arbitrary subset of variables can be known and one can ask for the joint probability of all other variables. For example if the values of <span class="arithmatex">\(X_{k+1}, X_{k+2}, \ldots, X_n\)</span> are known, the probability for <span class="arithmatex">\(X_1, X_2, \ldots, X_k\)</span> given these known values is</p>
<div class="arithmatex">\[p(X_1, X_2, \ldots, X_k|X_{k+1}, X_{k+2}, \ldots, X_n) = \frac{p(X_1, X_2, \ldots, X_n)}{p(X_{k+1}, X_{k+2}, \ldots, X_n)}\]</div>
<p>Applying this general definition to the case of three variables <span class="arithmatex">\(A\)</span>, <span class="arithmatex">\(B\)</span>, and <span class="arithmatex">\(C\)</span>, we have:</p>
<div class="arithmatex">\[p(A|B, C) = \frac{p(A, B, C)}{p(B, C)}\]</div>
<p>This is the fundamental definition of conditional probability for three variables. From this basic definition, we can derive the more useful Bayes' theorem form.</p>
<div class="arithmatex">\[p(A|B, C) = \frac{p(A, B, C)}{p(B, C)}\]</div>
<p>We can write the joint probability <span class="arithmatex">\(p(A, B, C)\)</span> using the chain rule:</p>
<div class="arithmatex">\[p(A, B, C) = p(B|A, C) \cdot p(A, C)\]</div>
<p>Substituting this into our basic definition:</p>
<div class="arithmatex">\[p(A|B, C) = \frac{p(B|A, C) \cdot p(A, C)}{p(B, C)}\]</div>
<p>We can write <span class="arithmatex">\(p(A, C)\)</span> as:</p>
<div class="arithmatex">\[p(A, C) = p(A|C) \cdot p(C)\]</div>
<div class="arithmatex">\[p(A|B, C) = \frac{p(B|A, C) \cdot p(A|C) \cdot p(C)}{p(B, C)}\]</div>
<p>Similarly, we can write <span class="arithmatex">\(p(B, C)\)</span> as:</p>
<div class="arithmatex">\[p(B, C) = p(B|C) \cdot p(C)\]</div>
<div class="arithmatex">\[p(A|B, C) = \frac{p(B|A, C) \cdot p(A|C) \cdot p(C)}{p(B|C) \cdot p(C)}\]</div>
<p>The <span class="arithmatex">\(p(C)\)</span> terms cancel out:</p>
<div class="arithmatex">\[p(A|B, C) = \frac{p(B|A, C) \cdot p(A|C)}{p(B|C)}\]</div>
<p>This is <strong>Bayes' theorem for three variables</strong>.</p>
<p>In our case, we have:</p>
<ul>
<li>
<p><span class="arithmatex">\(A = z_{t-1}\)</span> (the previous noisy image)</p>
</li>
<li>
<p><span class="arithmatex">\(B = z_t\)</span> (the current noisy image)</p>
</li>
<li>
<p><span class="arithmatex">\(C = x\)</span> (the original clean image)</p>
</li>
</ul>
<p>Substituting these into Bayes' theorem:</p>
<div class="arithmatex">\[q(z_{t-1}|z_t, x) = \frac{q(z_t|z_{t-1}, x)q(z_{t-1}|x)}{q(z_t|x)}\]</div>
<p>Since the forward process is Markovian, <span class="arithmatex">\(z_t\)</span> depends only on <span class="arithmatex">\(z_{t-1}\)</span>, not on <span class="arithmatex">\(x\)</span> directly:</p>
<div class="arithmatex">\[q(z_t|z_{t-1}, x) = q(z_t|z_{t-1})\]</div>
<p>This is because once we know <span class="arithmatex">\(z_{t-1}\)</span>, the additional knowledge of <span class="arithmatex">\(x\)</span> doesn't change the distribution of <span class="arithmatex">\(z_t\)</span>. We know from the diffusion kernel that:</p>
<div class="arithmatex">\[q(z_{t-1}|x) = \mathcal{N}(z_{t-1}|\sqrt{\bar{\alpha}_{t-1}} x, (1 - \bar{\alpha}_{t-1})I)\]</div>
<div class="arithmatex">\[q(z_t|x) = \mathcal{N}(z_t|\sqrt{\bar{\alpha}_t} x, (1 - \bar{\alpha}_t)I)\]</div>
<p>The forward process gives us:</p>
<div class="arithmatex">\[q(z_t|z_{t-1}) = \mathcal{N}(z_t|\sqrt{1 - \beta_t} z_{t-1}, \beta_t I)\]</div>
<p>Putting it all together:</p>
<div class="arithmatex">\[q(z_{t-1}|z_t, x) = \frac{q(z_t|z_{t-1})q(z_{t-1}|x)}{q(z_t|x)}\]</div>
<div class="arithmatex">\[= \frac{\mathcal{N}(z_t|\sqrt{1 - \beta_t} z_{t-1}, \beta_t I) \cdot \mathcal{N}(z_{t-1}|\sqrt{\bar{\alpha}_{t-1}} x, (1 - \bar{\alpha}_{t-1})I)}{\mathcal{N}(z_t|\sqrt{\bar{\alpha}_t} x, (1 - \bar{\alpha}_t)I)}\]</div>
<p>After algebraic manipulation, this simplifies to:</p>
<div class="arithmatex">\[q(z_{t-1}|z_t, x) = \mathcal{N}(z_{t-1}|\mu_t(x, z_t), \sigma_t^2 I)\]</div>
<p>where:</p>
<div class="arithmatex">\[\mu_t(x, z_t) = \frac{(1 - \bar{\alpha}_{t-1})\sqrt{1 - \beta_t} z_t + \sqrt{\bar{\alpha}_{t-1}} \beta_t x}{1 - \bar{\alpha}_t}\]</div>
<div class="arithmatex">\[\sigma_t^2 = \frac{\beta_t(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t}\]</div>
<h2 id="reverse-decoder">Reverse Decoder</h2>
<p>We have seen that the forward encoder model is defined by a sequence of Gaussian conditional distributions <span class="arithmatex">\(q(z_t|z_{t-1})\)</span> but that inverting this directly leads to a distribution <span class="arithmatex">\(q(z_{t-1}|z_t)\)</span> that is intractable, as it would require integrating over all possible values of the starting vector <span class="arithmatex">\(x\)</span> whose distribution is the unknown data distribution <span class="arithmatex">\(p_{data}(x)\)</span> that we wish to model. Instead, we will learn an approximation to the reverse distribution by using a distribution <span class="arithmatex">\(p(z_{t-1}|z_t, \theta)\)</span> governed by a deep neural network, where <span class="arithmatex">\(\theta\)</span> represents the network weights and biases. Once the network is trained, we can sample from the simple Gaussian distribution over <span class="arithmatex">\(z_T\)</span> and transform it into a sample from the data distribution <span class="arithmatex">\(p_{data}(x)\)</span> through a sequence of reverse sampling steps by repeated application of the trained network.</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      &copy; 2025 <a href="https://github.com/adi14041999"  target="_blank" rel="noopener">Aditya Prabhu</a>
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.sections", "toc.integrate", "navigation.top", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>