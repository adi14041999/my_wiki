
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A personal wiki for notes, ideas, and projects.">
      
      
      
        <link rel="canonical" href="https://adi14041999.github.io/my_wiki/AI/deep_generative_models/normalizing_flow_models/">
      
      
        <link rel="prev" href="../variational_autoencoders/">
      
      
        <link rel="next" href="../../../math/probability/probability_and_counting/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Normalizing flow models - My Wiki</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#normalizing-flow-models" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="My Wiki" class="md-header__button md-logo" aria-label="My Wiki" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            My Wiki
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Normalizing flow models
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../introduction/" class="md-tabs__link">
          
  
  
  AI

        </a>
      </li>
    
  

    
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../math/probability/probability_and_counting/" class="md-tabs__link">
          
  
  
  Math

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="My Wiki" class="md-nav__button md-logo" aria-label="My Wiki" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    My Wiki
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    AI
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            AI
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" checked>
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Deep Generative Models
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            Deep Generative Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../autoregressive_models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Autoregressive Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../variational_autoencoders/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Variational Autoencoders
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Normalizing flow models
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Normalizing flow models
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#change-of-variables-formula" class="md-nav__link">
    <span class="md-ellipsis">
      Change of Variables Formula
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Change of Variables Formula">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#univariate-case" class="md-nav__link">
    <span class="md-ellipsis">
      Univariate Case
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multivariate-case" class="md-nav__link">
    <span class="md-ellipsis">
      Multivariate Case
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#normalizing-flow-models-deep-dive" class="md-nav__link">
    <span class="md-ellipsis">
      Normalizing Flow Models deep dive
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Normalizing Flow Models deep dive">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#planar-flow" class="md-nav__link">
    <span class="md-ellipsis">
      Planar Flow
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#nice-and-realnvp" class="md-nav__link">
    <span class="md-ellipsis">
      NICE and RealNVP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autoregressive-flow-models" class="md-nav__link">
    <span class="md-ellipsis">
      Autoregressive Flow Models
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Math
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Math
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Probability
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            Probability
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/probability/probability_and_counting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Probability and Counting
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="normalizing-flow-models">Normalizing Flow Models</h1>
<p>So far we have learned two types of likelihood based generative models:</p>
<p><strong>Autoregressive Models</strong>: <span class="arithmatex">\(p_\theta(x) = \prod_{i=1}^N p_\theta(x_i|x_{&lt;i})\)</span></p>
<p><strong>Variational autoencoders</strong>: <span class="arithmatex">\(p_\theta(x) = \int p_\theta(x,z)dz\)</span></p>
<p>The two methods have relative strengths and weaknesses. Autoregressive models provide tractable likelihoods but no direct mechanism for learning features, whereas variational autoencoders can learn feature representations but have intractable marginal likelihoods.</p>
<h2 id="change-of-variables-formula">Change of Variables Formula</h2>
<p>In normalizing flows, we wish to map simple distributions (easy to sample and evaluate densities) to complex ones (learned via data). The change of variables formula describes how to evaluate densities of a random variable that is a deterministic transformation from another variable.</p>
<p>Let's start with the univariate case and then generalize to multivariate random variables.</p>
<h3 id="univariate-case">Univariate Case</h3>
<p>Consider two random variables <span class="arithmatex">\(Z\)</span> and <span class="arithmatex">\(X\)</span> related by a strictly monotonic function <span class="arithmatex">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span> such that <span class="arithmatex">\(X = f(Z)\)</span>. We want to find the probability density function of <span class="arithmatex">\(X\)</span> in terms of the density of <span class="arithmatex">\(Z\)</span>.</p>
<p>The key insight comes from the fact that probabilities must be preserved under the transformation. For any interval <span class="arithmatex">\([a, b]\)</span> in the <span class="arithmatex">\(X\)</span> space:</p>
<div class="arithmatex">\[P(a \leq X \leq b) = P(f^{-1}(a) \leq Z \leq f^{-1}(b))\]</div>
<p>This can be written as:</p>
<div class="arithmatex">\[\int_a^b p_X(x) dx = \int_{f^{-1}(a)}^{f^{-1}(b)} p_Z(z) dz\]</div>
<p>To perform the substitution <span class="arithmatex">\(z = f^{-1}(x)\)</span>, we need to express <span class="arithmatex">\(dz\)</span> in terms of <span class="arithmatex">\(dx\)</span>. Since <span class="arithmatex">\(z = f^{-1}(x)\)</span>, we can use the chain rule to find:</p>
<div class="arithmatex">\[\frac{dz}{dx} = \frac{d}{dx}f^{-1}(x) = \frac{1}{f'(f^{-1}(x))}\]</div>
<p>This follows from the inverse function theorem: if <span class="arithmatex">\(y = f(x)\)</span>, then <span class="arithmatex">\(\frac{dx}{dy} = \frac{1}{f'(x)}\)</span>.</p>
<p>Therefore, <span class="arithmatex">\(dz = \frac{1}{f'(f^{-1}(x))} dx\)</span>. However, we need to take the absolute value because probability densities must be non-negative. If <span class="arithmatex">\(f'(f^{-1}(x)) &lt; 0\)</span> (meaning <span class="arithmatex">\(f\)</span> is decreasing), then <span class="arithmatex">\(\frac{1}{f'(f^{-1}(x))} &lt; 0\)</span>, which would make the density negative. Therefore, we use:</p>
<div class="arithmatex">\[dz = \frac{1}{|f'(f^{-1}(x))|} dx\]</div>
<p>Substituting this into our integral:</p>
<div class="arithmatex">\[\int_a^b p_X(x) dx = \int_{f^{-1}(a)}^{f^{-1}(b)} p_Z(z) dz = \int_a^b p_Z(f^{-1}(x)) \cdot \frac{1}{|f'(f^{-1}(x))|} dx\]</div>
<p>Since this equality must hold for all intervals <span class="arithmatex">\([a, b]\)</span>, the integrands must be equal:</p>
<div class="arithmatex">\[p_X(x) = p_Z(f^{-1}(x)) \cdot \frac{1}{|f'(f^{-1}(x))|}\]</div>
<p>This is the univariate change of variables formula. The factor <span class="arithmatex">\(\frac{1}{|f'(f^{-1}(x))|}\)</span> accounts for how the transformation stretches or compresses the probability mass.</p>
<p><strong>Why should <span class="arithmatex">\(f\)</span> be monotonic?</strong> The monotonicity requirement ensures that <span class="arithmatex">\(f\)</span> is invertible (one-to-one), which is crucial for the change of variables formula to work correctly. If <span class="arithmatex">\(f\)</span> were not monotonic, there could be multiple values of <span class="arithmatex">\(z\)</span> that map to the same value of <span class="arithmatex">\(x\)</span>, making the inverse function <span class="arithmatex">\(f^{-1}\)</span> ill-defined. This would violate the fundamental assumption that we can uniquely determine the original variable <span class="arithmatex">\(z\)</span> from the transformed variable <span class="arithmatex">\(x\)</span>.</p>
<p>For example, if <span class="arithmatex">\(f(z) = z^2\)</span> (which is not monotonic on <span class="arithmatex">\(\mathbb{R}\)</span>), then both <span class="arithmatex">\(z = 2\)</span> and <span class="arithmatex">\(z = -2\)</span> map to <span class="arithmatex">\(x = 4\)</span>. This creates ambiguity in the inverse mapping and would require special handling to account for multiple pre-images.</p>
<h3 id="multivariate-case">Multivariate Case</h3>
<p>For the multivariate case, we have random variables <span class="arithmatex">\(\mathbf{Z}\)</span> and <span class="arithmatex">\(\mathbf{X}\)</span> related by a bijective function <span class="arithmatex">\(f: \mathbb{R}^n \rightarrow \mathbb{R}^n\)</span> such that <span class="arithmatex">\(\mathbf{X} = f(\mathbf{Z})\)</span>.</p>
<p>The key insight is that the probability mass in any region must be preserved under the transformation. For any region <span class="arithmatex">\(A\)</span> in the <span class="arithmatex">\(\mathbf{X}\)</span> space:</p>
<div class="arithmatex">\[P(\mathbf{X} \in A) = P(\mathbf{Z} \in f^{-1}(A))\]</div>
<p>This can be written as:</p>
<div class="arithmatex">\[\int_A p_X(\mathbf{x}) d\mathbf{x} = \int_{f^{-1}(A)} p_Z(\mathbf{z}) d\mathbf{z}\]</div>
<p>To perform the multivariate substitution <span class="arithmatex">\(\mathbf{z} = f^{-1}(\mathbf{x})\)</span>, we need to understand how the volume element <span class="arithmatex">\(d\mathbf{z}\)</span> transforms. The Jacobian matrix <span class="arithmatex">\(\frac{\partial f^{-1}(\mathbf{x})}{\partial \mathbf{x}}\)</span> is an <span class="arithmatex">\(n \times n\)</span> matrix where:</p>
<div class="arithmatex">\[\left[\frac{\partial f^{-1}(\mathbf{x})}{\partial \mathbf{x}}\right]_{ij} = \frac{\partial f^{-1}_i(\mathbf{x})}{\partial x_j}\]</div>
<p>This matrix describes how small changes in <span class="arithmatex">\(\mathbf{x}\)</span> correspond to changes in <span class="arithmatex">\(\mathbf{z}\)</span>. In multivariate calculus, when we perform a change of variables <span class="arithmatex">\(\mathbf{z} = f^{-1}(\mathbf{x})\)</span>, the volume element transforms as:</p>
<div class="arithmatex">\[d\mathbf{z} = \left|\det\left(\frac{\partial f^{-1}(\mathbf{x})}{\partial \mathbf{x}}\right)\right| d\mathbf{x}\]</div>
<p>This is the multivariate generalization of the univariate substitution <span class="arithmatex">\(dz = \frac{1}{|f'(f^{-1}(x))|} dx\)</span>. The determinant of the Jacobian matrix measures how the transformation affects the volume of a small region:
- If <span class="arithmatex">\(|\det(J)| &gt; 1\)</span>, the transformation expands volume
- If <span class="arithmatex">\(|\det(J)| &lt; 1\)</span>, the transformation contracts volume<br />
- If <span class="arithmatex">\(|\det(J)| = 1\)</span>, the transformation preserves volume</p>
<p>Substituting this into our integral:</p>
<div class="arithmatex">\[\int_A p_X(\mathbf{x}) d\mathbf{x} = \int_{f^{-1}(A)} p_Z(\mathbf{z}) d\mathbf{z} = \int_A p_Z(f^{-1}(\mathbf{x})) \left|\det\left(\frac{\partial f^{-1}(\mathbf{x})}{\partial \mathbf{x}}\right)\right| d\mathbf{x}\]</div>
<p>Since this equality must hold for all regions <span class="arithmatex">\(A\)</span>, the integrands must be equal:</p>
<div class="arithmatex">\[p_X(\mathbf{x}) = p_Z(f^{-1}(\mathbf{x})) \left|\det\left(\frac{\partial f^{-1}(\mathbf{x})}{\partial \mathbf{x}}\right)\right|\]</div>
<p>This is the multivariate change of variables formula. The determinant of the Jacobian matrix accounts for how the transformation affects the volume of probability mass.</p>
<p><strong>Alternative Form Using Forward Mapping:</strong>
Using the property that <span class="arithmatex">\(\det(A^{-1}) = \det(A)^{-1}\)</span> for any invertible matrix <span class="arithmatex">\(A\)</span>, we can rewrite this as:</p>
<div class="arithmatex">\[p_X(\mathbf{x}) = p_Z(\mathbf{z}) \left|\det\left(\frac{\partial f(\mathbf{z})}{\partial \mathbf{z}}\right)\right|^{-1}\]</div>
<p>This form is often more convenient in practice because it uses the forward mapping <span class="arithmatex">\(f\)</span> rather than the inverse mapping <span class="arithmatex">\(f^{-1}\)</span>.</p>
<p><strong>Final result</strong>: Let <span class="arithmatex">\(Z\)</span> and <span class="arithmatex">\(X\)</span> be random variables which are related by a mapping <span class="arithmatex">\(f: \mathbb{R}^n \rightarrow \mathbb{R}^n\)</span> such that <span class="arithmatex">\(X = f(Z)\)</span> and <span class="arithmatex">\(Z = f^{-1}(X)\)</span>. Then</p>
<div class="arithmatex">\[p_X(\mathbf{x}) = p_Z(f^{-1}(\mathbf{x})) \left|\det\left(\frac{\partial f^{-1}(\mathbf{x})}{\partial \mathbf{x}}\right)\right|\]</div>
<p>There are several things to note here:</p>
<ul>
<li><span class="arithmatex">\(\mathbf{x}\)</span> and <span class="arithmatex">\(\mathbf{z}\)</span> need to be continuous and have the same dimension.</li>
<li><span class="arithmatex">\(\frac{\partial f^{-1}(\mathbf{x})}{\partial \mathbf{x}}\)</span> is a matrix of dimension <span class="arithmatex">\(n \times n\)</span>, where each entry at location <span class="arithmatex">\((i,j)\)</span> is defined as <span class="arithmatex">\(\frac{\partial f^{-1}(\mathbf{x})_i}{\partial x_j}\)</span>. This matrix is also known as the Jacobian matrix.</li>
<li><span class="arithmatex">\(\det(A)\)</span> denotes the determinant of a square matrix <span class="arithmatex">\(A\)</span>.</li>
</ul>
<p>For any invertible matrix <span class="arithmatex">\(A\)</span>, <span class="arithmatex">\(\det(A^{-1}) = \det(A)^{-1}\)</span>, so for <span class="arithmatex">\(\mathbf{z} = f^{-1}(\mathbf{x})\)</span> we have</p>
<div class="arithmatex">\[p_X(\mathbf{x}) = p_Z(\mathbf{z}) \left|\det\left(\frac{\partial f(\mathbf{z})}{\partial \mathbf{z}}\right)\right|^{-1}\]</div>
<p>If <span class="arithmatex">\(\left|\det\left(\frac{\partial f(\mathbf{z})}{\partial \mathbf{z}}\right)\right| = 1\)</span>, then the mapping is volume preserving, which means that the transformed distribution <span class="arithmatex">\(p_X\)</span> will have the same "volume" compared to the original one <span class="arithmatex">\(p_Z\)</span>.</p>
<h2 id="normalizing-flow-models-deep-dive">Normalizing Flow Models deep dive</h2>
<p>Let us consider a directed, latent-variable model over observed variables <span class="arithmatex">\(X\)</span> and latent variables <span class="arithmatex">\(Z\)</span>. In a normalizing flow model, the mapping between <span class="arithmatex">\(Z\)</span> and <span class="arithmatex">\(X\)</span>, given by <span class="arithmatex">\(f_\theta: \mathbb{R}^n \rightarrow \mathbb{R}^n\)</span>, is deterministic and invertible such that <span class="arithmatex">\(X = f_\theta(Z)\)</span> and <span class="arithmatex">\(Z = f^{-1}_\theta(X)\)</span>.</p>
<p>Using change of variables, the marginal likelihood <span class="arithmatex">\(p(x)\)</span> is given by</p>
<div class="arithmatex">\[p_X(\mathbf{x}; \theta) = p_Z(f^{-1}_\theta(\mathbf{x})) \left|\det\left(\frac{\partial f^{-1}_\theta(\mathbf{x})}{\partial \mathbf{x}}\right)\right|\]</div>
<p>The name "normalizing flow" can be interpreted as the following:</p>
<ul>
<li>
<p><strong>"Normalizing"</strong> means that the change of variables gives a normalized density after applying an invertible transformation. When we transform a random variable through an invertible function, the resulting density automatically integrates to 1 (is normalized) because the change of variables formula preserves the total probability mass. This is different from other methods where we might need to explicitly normalize or approximate the density.</p>
</li>
<li>
<p><strong>"Flow"</strong> means that the invertible transformations can be composed with each other to create more complex invertible transformations. If we have two invertible functions <span class="arithmatex">\(f_1\)</span> and <span class="arithmatex">\(f_2\)</span>, then their composition <span class="arithmatex">\(f_2 \circ f_1\)</span> is also invertible. This allows us to build complex transformations by chaining simpler ones, creating a "flow" of transformations.</p>
</li>
</ul>
<p>Different from autoregressive models and variational autoencoders, deep normalizing flow models require specific architectural structures:</p>
<ol>
<li>
<p><strong>The input and output dimensions must be the same</strong> - This is necessary for the transformation to be invertible. If the dimensions don't match, we can't uniquely map back and forth between the spaces.</p>
</li>
<li>
<p><strong>The transformation must be invertible</strong> - This is fundamental to the change of variables formula and allows us to compute both the forward transformation (for sampling) and the inverse transformation (for density evaluation).</p>
</li>
<li>
<p><strong>Computing the determinant of the Jacobian needs to be efficient (and differentiable)</strong> - The change of variables formula requires computing the determinant of the Jacobian matrix. For high-dimensional spaces, this can be computationally expensive, so we need architectures that make this computation tractable.</p>
</li>
</ol>
<p>Next, we introduce several popular forms of flow models that satisfy these properties.</p>
<h3 id="planar-flow">Planar Flow</h3>
<p>The Planar Flow introduces the following invertible transformation:</p>
<div class="arithmatex">\[\mathbf{x} = f_\theta(\mathbf{z}) = \mathbf{z} + \mathbf{u}h(\mathbf{w}^\top\mathbf{z} + b)\]</div>
<p>where <span class="arithmatex">\(\mathbf{u}, \mathbf{w}, b\)</span> are parameters.</p>
<p>The absolute value of the determinant of the Jacobian is given by:</p>
<div class="arithmatex">\[\left|\det\left(\frac{\partial f(\mathbf{z})}{\partial \mathbf{z}}\right)\right| = |1 + h'(\mathbf{w}^\top\mathbf{z} + b)\mathbf{u}^\top\mathbf{w}|\]</div>
<p>However, <span class="arithmatex">\(\mathbf{u}, \mathbf{w}, b, h(\cdot)\)</span> need to be restricted in order to be invertible. For example, <span class="arithmatex">\(h = \tanh\)</span> and <span class="arithmatex">\(h'(\mathbf{w}^\top\mathbf{z} + b)\mathbf{u}^\top\mathbf{w} \geq -1\)</span>. Note that while <span class="arithmatex">\(f_\theta(\mathbf{z})\)</span> is invertible, computing <span class="arithmatex">\(f^{-1}_\theta(\mathbf{z})\)</span> could be difficult analytically. The following models address this problem, where both <span class="arithmatex">\(f_\theta\)</span> and <span class="arithmatex">\(f^{-1}_\theta\)</span> have simple analytical forms.</p>
<h3 id="nice-and-realnvp">NICE and RealNVP</h3>
<p>The Nonlinear Independent Components Estimation (NICE) model and Real Non-Volume Preserving (RealNVP) model compose two kinds of invertible transformations: additive coupling layers and rescaling layers. The coupling layer in NICE partitions a variable <span class="arithmatex">\(\mathbf{z}\)</span> into two disjoint subsets, say <span class="arithmatex">\(\mathbf{z}_1\)</span> and <span class="arithmatex">\(\mathbf{z}_2\)</span>. Then it applies the following transformation:</p>
<p><strong>Forward mapping <span class="arithmatex">\(\mathbf{z} \rightarrow \mathbf{x}\)</span>:</strong></p>
<ul>
<li><span class="arithmatex">\(\mathbf{x}_1 = \mathbf{z}_1\)</span>, which is an identity mapping.</li>
<li><span class="arithmatex">\(\mathbf{x}_2 = \mathbf{z}_2 + m_\theta(\mathbf{z}_1)\)</span>, where <span class="arithmatex">\(m_\theta\)</span> is a neural network.</li>
</ul>
<p><strong>Inverse mapping <span class="arithmatex">\(\mathbf{x} \rightarrow \mathbf{z}\)</span>:</strong></p>
<ul>
<li><span class="arithmatex">\(\mathbf{z}_1 = \mathbf{x}_1\)</span>, which is an identity mapping.</li>
<li><span class="arithmatex">\(\mathbf{z}_2 = \mathbf{x}_2 - m_\theta(\mathbf{x}_1)\)</span>, which is the inverse of the forward transformation.</li>
</ul>
<p>Therefore, the Jacobian of the forward mapping is lower triangular, whose determinant is simply the product of the elements on the diagonal, which is 1. Therefore, this defines a volume preserving transformation. RealNVP adds scaling factors to the transformation:</p>
<div class="arithmatex">\[\mathbf{x}_2 = \exp(s_\theta(\mathbf{z}_1)) \odot \mathbf{z}_2 + m_\theta(\mathbf{z}_1)\]</div>
<p>where <span class="arithmatex">\(\odot\)</span> denotes elementwise product. This results in a non-volume preserving transformation.</p>
<h3 id="autoregressive-flow-models">Autoregressive Flow Models</h3>
<p>Some autoregressive models can also be interpreted as flow models. For a Gaussian autoregressive model, one receives some Gaussian noise for each dimension of <span class="arithmatex">\(\mathbf{x}\)</span>, which can be treated as the latent variables <span class="arithmatex">\(\mathbf{z}\)</span>. Such transformations are also invertible, meaning that given <span class="arithmatex">\(\mathbf{x}\)</span> and the model parameters, we can obtain <span class="arithmatex">\(\mathbf{z}\)</span> exactly.</p>
<p><strong>Masked Autoregressive Flow (MAF)</strong> uses this interpretation, where the forward mapping is an autoregressive model. However, sampling is sequential and slow, in <span class="arithmatex">\(O(n)\)</span> time where <span class="arithmatex">\(n\)</span> is the dimension of the samples.</p>
<p>To address the sampling problem, the <strong>Inverse Autoregressive Flow (IAF)</strong> simply inverts the generating process. In this case, the sampling (generation), is still parallelized. However, computing the likelihood of new data points is slow.</p>
<p><strong>Forward mapping from <span class="arithmatex">\(\mathbf{z} \rightarrow \mathbf{x}\)</span> (parallel):</strong></p>
<ol>
<li>
<p>Sample <span class="arithmatex">\(z_i \sim \mathcal{N}(0,1)\)</span> for <span class="arithmatex">\(i = 1, \ldots, n\)</span></p>
</li>
<li>
<p>Compute all <span class="arithmatex">\(\mu_i, \alpha_i\)</span> (can be done in parallel)</p>
</li>
<li>
<p>Let <span class="arithmatex">\(x_1 = \exp(\alpha_1)z_1 + \mu_1\)</span></p>
</li>
<li>
<p>Let <span class="arithmatex">\(x_2 = \exp(\alpha_2)z_2 + \mu_2\)</span></p>
</li>
<li>
<p><span class="arithmatex">\(\ldots\)</span></p>
</li>
</ol>
<p><strong>Inverse mapping from <span class="arithmatex">\(\mathbf{x} \rightarrow \mathbf{z}\)</span> (sequential):</strong></p>
<ol>
<li>
<p>Let <span class="arithmatex">\(z_1 = (x_1 - \mu_1)/\exp(\alpha_1)\)</span></p>
</li>
<li>
<p>Compute <span class="arithmatex">\(\mu_2(z_1), \alpha_2(z_1)\)</span></p>
</li>
<li>
<p>Let <span class="arithmatex">\(z_2 = (x_2 - \mu_2)/\exp(\alpha_2)\)</span></p>
</li>
<li>
<p>Compute <span class="arithmatex">\(\mu_3(z_1,z_2), \alpha_3(z_1,z_2)\)</span></p>
</li>
<li>
<p><span class="arithmatex">\(\ldots\)</span></p>
</li>
</ol>
<p><strong>Key insight:</strong> Fast to sample from, slow to evaluate likelihoods of data points (train).</p>
<p><strong>Efficient Likelihood for Generated Points:</strong>
However, for generated points the likelihood can be computed efficiently (since the noise are already obtained). When we generate samples using IAF, we start with known noise values <span class="arithmatex">\(\mathbf{z}\)</span> and transform them to get <span class="arithmatex">\(\mathbf{x}\)</span>. Since we already have the noise values, we don't need to perform the expensive sequential inverse mapping to recover them. We can directly compute the likelihood using the change of variables formula:</p>
<div class="arithmatex">\[\log p(\mathbf{x}) = \log p(\mathbf{z}) - \sum_{i=1}^n \alpha_i\]</div>
<p>where we already know all the <span class="arithmatex">\(\alpha_i\)</span> values from the forward pass. This is much faster than the <span class="arithmatex">\(O(n)\)</span> sequential computation required for arbitrary data points.</p>
<p><strong>Derivation of the Change of Variables Formula for IAF:</strong></p>
<p>Let's derive how we get this formula. Starting with the general change of variables formula:</p>
<div class="arithmatex">\[\log p(\mathbf{x}) = \log p(\mathbf{z}) + \log \left|\det\left(\frac{\partial \mathbf{z}}{\partial \mathbf{x}}\right)\right|\]</div>
<p>For IAF, the forward transformation is:</p>
<div class="arithmatex">\[x_i = \exp(\alpha_i)z_i + \mu_i\]</div>
<p>The inverse transformation is:</p>
<div class="arithmatex">\[z_i = \frac{x_i - \mu_i}{\exp(\alpha_i)}\]</div>
<p>The Jacobian matrix <span class="arithmatex">\(\frac{\partial \mathbf{z}}{\partial \mathbf{x}}\)</span> is diagonal because each <span class="arithmatex">\(z_i\)</span> only depends on <span class="arithmatex">\(x_i\)</span>:</p>
<div class="arithmatex">\[\frac{\partial z_i}{\partial x_j} = \begin{cases} 
\frac{1}{\exp(\alpha_i)} &amp; \text{if } i = j \\
0 &amp; \text{if } i \neq j
\end{cases}\]</div>
<p>Therefore, the determinant is the product of the diagonal elements:</p>
<div class="arithmatex">\[\det\left(\frac{\partial \mathbf{z}}{\partial \mathbf{x}}\right) = \prod_{i=1}^n \frac{1}{\exp(\alpha_i)} = \exp\left(-\sum_{i=1}^n \alpha_i\right)\]</div>
<p>Taking the absolute value and logarithm:</p>
<div class="arithmatex">\[\log \left|\det\left(\frac{\partial \mathbf{z}}{\partial \mathbf{x}}\right)\right| = \log \exp\left(-\sum_{i=1}^n \alpha_i\right) = -\sum_{i=1}^n \alpha_i\]</div>
<p>Substituting back into the change of variables formula:</p>
<div class="arithmatex">\[\log p(\mathbf{x}) = \log p(\mathbf{z}) - \sum_{i=1}^n \alpha_i\]</div>
<p>This derivation shows why the likelihood computation is efficient for generated samples - we already have all the <span class="arithmatex">\(\alpha_i\)</span> values from the forward pass, so we just need to sum them up.</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      &copy; 2025 <a href="https://github.com/adi14041999"  target="_blank" rel="noopener">Aditya Prabhu</a>
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.sections", "toc.integrate", "navigation.top", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>